2023/02/05 22:37:08 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) [GCC 10.4.0]
    CUDA available: True
    numpy_random_seed: 2099256647
    GPU 0: TITAN Xp
    CUDA_HOME: None
    GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
    PyTorch: 1.12.1
    PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.13.1
    OpenCV: 4.7.0
    MMEngine: 0.4.0

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: None
    deterministic: False
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2023/02/05 22:37:08 - mmengine - INFO - Config:
default_scope = 'mmcls'
default_hooks = dict(
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=100),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(type='CheckpointHook', interval=1),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    visualization=dict(type='VisualizationHook', enable=False))
env_cfg = dict(
    cudnn_benchmark=False,
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='nccl'))
vis_backends = [dict(type='LocalVisBackend')]
visualizer = dict(
    type='ClsVisualizer', vis_backends=[dict(type='LocalVisBackend')])
log_level = 'INFO'
load_from = '/home/ccx/code/python/mmclassification-dev-1.x/checkpoints/mobilenet_v2_batch256_imagenet_20200708-3b2dc3af.pth'
resume = False
randomness = dict(seed=None, deterministic=False)
model = dict(
    type='ImageClassifier',
    backbone=dict(type='MobileNetV2', widen_factor=1.0),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='LinearClsHead',
        num_classes=5,
        in_channels=1280,
        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),
        topk=(1, 5)))
dataset_type = 'CustomDataset'
data_preprocessor = dict(
    num_classes=5,
    mean=[123.675, 116.28, 103.53],
    std=[58.395, 57.12, 57.375],
    to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='RandomResizedCrop', scale=224, backend='pillow'),
    dict(type='RandomFlip', prob=0.5, direction='horizontal'),
    dict(type='PackClsInputs')
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='ResizeEdge', scale=256, edge='short', backend='pillow'),
    dict(type='CenterCrop', crop_size=224),
    dict(type='PackClsInputs')
]
train_dataloader = dict(
    pin_memory=True,
    persistent_workers=True,
    collate_fn=dict(type='default_collate'),
    batch_size=32,
    num_workers=5,
    dataset=dict(
        type='CustomDataset',
        data_root='data/flower_dataset',
        ann_file='train.txt',
        data_prefix='train',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='RandomResizedCrop', scale=224, backend='pillow'),
            dict(type='RandomFlip', prob=0.5, direction='horizontal'),
            dict(type='PackClsInputs')
        ]),
    sampler=dict(type='DefaultSampler', shuffle=True))
train_evaluator = dict(type='Accuracy', topk=(1, 5))
val_dataloader = dict(
    pin_memory=True,
    persistent_workers=True,
    collate_fn=dict(type='default_collate'),
    batch_size=32,
    num_workers=5,
    dataset=dict(
        type='CustomDataset',
        data_root='data/flower_dataset',
        ann_file='val.txt',
        data_prefix='val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='ResizeEdge', scale=256, edge='short', backend='pillow'),
            dict(type='CenterCrop', crop_size=224),
            dict(type='PackClsInputs')
        ]),
    sampler=dict(type='DefaultSampler', shuffle=False))
val_evaluator = dict(type='Accuracy', topk=(1, 5))
test_dataloader = dict(
    pin_memory=True,
    persistent_workers=True,
    collate_fn=dict(type='default_collate'),
    batch_size=32,
    num_workers=5,
    dataset=dict(
        type='CustomDataset',
        data_root='data/flower_dataset',
        ann_file='val.txt',
        data_prefix='val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='ResizeEdge', scale=256, edge='short', backend='pillow'),
            dict(type='CenterCrop', crop_size=224),
            dict(type='PackClsInputs')
        ]),
    sampler=dict(type='DefaultSampler', shuffle=False))
test_evaluator = dict(type='Accuracy', topk=(1, 5))
optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.00045, momentum=0.9, weight_decay=4e-05))
param_scheduler = dict(type='StepLR', by_epoch=True, step_size=1, gamma=0.98)
auto_scale_lr = dict(base_batch_size=256)
train_cfg = dict(by_epoch=True, max_epochs=15, val_interval=1)
val_cfg = dict()
test_cfg = dict()
log_config = dict(interval=6, hooks=[dict(type='TextLoggerHook')])
launcher = 'none'
work_dir = './work_dirs/mobilenet-v2_my'

2023/02/05 22:37:10 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2023/02/05 22:37:10 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
Name of parameter - Initialization information

backbone.conv1.conv.weight - torch.Size([32, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.conv1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv.0.conv.weight - torch.Size([32, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.conv.0.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv.0.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv.1.conv.weight - torch.Size([16, 32, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.conv.1.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv.1.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv.0.conv.weight - torch.Size([96, 16, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.conv.0.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv.0.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv.1.conv.weight - torch.Size([96, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.conv.1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv.1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv.2.conv.weight - torch.Size([24, 96, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.conv.2.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv.2.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv.0.conv.weight - torch.Size([144, 24, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.conv.0.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv.0.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv.1.conv.weight - torch.Size([144, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.conv.1.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv.1.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv.2.conv.weight - torch.Size([24, 144, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.conv.2.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv.2.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv.0.conv.weight - torch.Size([144, 24, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.conv.0.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv.0.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv.1.conv.weight - torch.Size([144, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.conv.1.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv.1.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv.2.conv.weight - torch.Size([32, 144, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.conv.2.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv.2.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv.0.conv.weight - torch.Size([192, 32, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.conv.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv.1.conv.weight - torch.Size([192, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.conv.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv.2.conv.weight - torch.Size([32, 192, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.conv.2.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv.2.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv.0.conv.weight - torch.Size([192, 32, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.conv.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv.1.conv.weight - torch.Size([192, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.conv.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv.2.conv.weight - torch.Size([32, 192, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.conv.2.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv.2.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv.0.conv.weight - torch.Size([192, 32, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.conv.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv.1.conv.weight - torch.Size([192, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.conv.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv.2.conv.weight - torch.Size([64, 192, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.conv.2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv.2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv.0.conv.weight - torch.Size([384, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.conv.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv.1.conv.weight - torch.Size([384, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.conv.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv.2.conv.weight - torch.Size([64, 384, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.conv.2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv.2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv.0.conv.weight - torch.Size([384, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.conv.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv.1.conv.weight - torch.Size([384, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.conv.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv.2.conv.weight - torch.Size([64, 384, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.conv.2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv.2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.3.conv.0.conv.weight - torch.Size([384, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.3.conv.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.3.conv.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.3.conv.1.conv.weight - torch.Size([384, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.3.conv.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.3.conv.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.3.conv.2.conv.weight - torch.Size([64, 384, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.3.conv.2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.3.conv.2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.0.conv.0.conv.weight - torch.Size([384, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.0.conv.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.0.conv.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.0.conv.1.conv.weight - torch.Size([384, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.0.conv.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.0.conv.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.0.conv.2.conv.weight - torch.Size([96, 384, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.0.conv.2.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.0.conv.2.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.1.conv.0.conv.weight - torch.Size([576, 96, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.1.conv.0.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.1.conv.0.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.1.conv.1.conv.weight - torch.Size([576, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.1.conv.1.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.1.conv.1.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.1.conv.2.conv.weight - torch.Size([96, 576, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.1.conv.2.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.1.conv.2.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.2.conv.0.conv.weight - torch.Size([576, 96, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.2.conv.0.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.2.conv.0.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.2.conv.1.conv.weight - torch.Size([576, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.2.conv.1.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.2.conv.1.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.2.conv.2.conv.weight - torch.Size([96, 576, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.2.conv.2.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.2.conv.2.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.0.conv.0.conv.weight - torch.Size([576, 96, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.0.conv.0.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.0.conv.0.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.0.conv.1.conv.weight - torch.Size([576, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.0.conv.1.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.0.conv.1.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.0.conv.2.conv.weight - torch.Size([160, 576, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.0.conv.2.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.0.conv.2.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.1.conv.0.conv.weight - torch.Size([960, 160, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.1.conv.0.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.1.conv.0.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.1.conv.1.conv.weight - torch.Size([960, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.1.conv.1.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.1.conv.1.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.1.conv.2.conv.weight - torch.Size([160, 960, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.1.conv.2.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.1.conv.2.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.2.conv.0.conv.weight - torch.Size([960, 160, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.2.conv.0.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.2.conv.0.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.2.conv.1.conv.weight - torch.Size([960, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.2.conv.1.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.2.conv.1.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.2.conv.2.conv.weight - torch.Size([160, 960, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.2.conv.2.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.2.conv.2.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.0.conv.0.conv.weight - torch.Size([960, 160, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer7.0.conv.0.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.0.conv.0.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.0.conv.1.conv.weight - torch.Size([960, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer7.0.conv.1.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.0.conv.1.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.0.conv.2.conv.weight - torch.Size([320, 960, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer7.0.conv.2.bn.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.0.conv.2.bn.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.conv2.conv.weight - torch.Size([1280, 320, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv2.bn.weight - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.conv2.bn.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

head.fc.weight - torch.Size([5, 1280]): 
NormalInit: mean=0, std=0.01, bias=0 

head.fc.bias - torch.Size([5]): 
NormalInit: mean=0, std=0.01, bias=0 
2023/02/05 22:37:11 - mmengine - INFO - Load checkpoint from /home/ccx/code/python/mmclassification-dev-1.x/checkpoints/mobilenet_v2_batch256_imagenet_20200708-3b2dc3af.pth
2023/02/05 22:37:11 - mmengine - INFO - Checkpoints will be saved to /home/ccx/code/python/mmclassification-dev-1.x/work_dirs/mobilenet-v2_my.
2023/02/05 22:37:17 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:37:17 - mmengine - INFO - Saving checkpoint at 1 epochs
2023/02/05 22:37:19 - mmengine - INFO - Epoch(val) [1][18/18]  accuracy/top1: 93.8380  accuracy/top5: 100.0000
2023/02/05 22:37:25 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:37:25 - mmengine - INFO - Saving checkpoint at 2 epochs
2023/02/05 22:37:26 - mmengine - INFO - Epoch(val) [2][18/18]  accuracy/top1: 95.2465  accuracy/top5: 100.0000
2023/02/05 22:37:32 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:37:32 - mmengine - INFO - Saving checkpoint at 3 epochs
2023/02/05 22:37:33 - mmengine - INFO - Epoch(val) [3][18/18]  accuracy/top1: 94.7183  accuracy/top5: 100.0000
2023/02/05 22:37:40 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:37:40 - mmengine - INFO - Saving checkpoint at 4 epochs
2023/02/05 22:37:41 - mmengine - INFO - Epoch(val) [4][18/18]  accuracy/top1: 96.1268  accuracy/top5: 100.0000
2023/02/05 22:37:47 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:37:47 - mmengine - INFO - Saving checkpoint at 5 epochs
2023/02/05 22:37:48 - mmengine - INFO - Epoch(val) [5][18/18]  accuracy/top1: 95.5986  accuracy/top5: 100.0000
2023/02/05 22:37:55 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:37:55 - mmengine - INFO - Saving checkpoint at 6 epochs
2023/02/05 22:37:56 - mmengine - INFO - Epoch(val) [6][18/18]  accuracy/top1: 95.9507  accuracy/top5: 100.0000
2023/02/05 22:38:03 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:38:03 - mmengine - INFO - Saving checkpoint at 7 epochs
2023/02/05 22:38:04 - mmengine - INFO - Epoch(val) [7][18/18]  accuracy/top1: 95.9507  accuracy/top5: 100.0000
2023/02/05 22:38:10 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:38:10 - mmengine - INFO - Saving checkpoint at 8 epochs
2023/02/05 22:38:11 - mmengine - INFO - Epoch(val) [8][18/18]  accuracy/top1: 96.1268  accuracy/top5: 100.0000
2023/02/05 22:38:18 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:38:18 - mmengine - INFO - Saving checkpoint at 9 epochs
2023/02/05 22:38:19 - mmengine - INFO - Epoch(val) [9][18/18]  accuracy/top1: 95.7747  accuracy/top5: 100.0000
2023/02/05 22:38:25 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:38:25 - mmengine - INFO - Saving checkpoint at 10 epochs
2023/02/05 22:38:26 - mmengine - INFO - Epoch(val) [10][18/18]  accuracy/top1: 96.4789  accuracy/top5: 100.0000
2023/02/05 22:38:33 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:38:33 - mmengine - INFO - Saving checkpoint at 11 epochs
2023/02/05 22:38:34 - mmengine - INFO - Epoch(val) [11][18/18]  accuracy/top1: 96.4789  accuracy/top5: 100.0000
2023/02/05 22:38:41 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:38:41 - mmengine - INFO - Saving checkpoint at 12 epochs
2023/02/05 22:38:42 - mmengine - INFO - Epoch(val) [12][18/18]  accuracy/top1: 96.3028  accuracy/top5: 100.0000
2023/02/05 22:38:48 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:38:48 - mmengine - INFO - Saving checkpoint at 13 epochs
2023/02/05 22:38:49 - mmengine - INFO - Epoch(val) [13][18/18]  accuracy/top1: 96.3028  accuracy/top5: 100.0000
2023/02/05 22:38:55 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:38:56 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:38:56 - mmengine - INFO - Saving checkpoint at 14 epochs
2023/02/05 22:38:57 - mmengine - INFO - Epoch(val) [14][18/18]  accuracy/top1: 96.6549  accuracy/top5: 100.0000
2023/02/05 22:39:04 - mmengine - INFO - Exp name: mobilenet-v2_my_20230205_223708
2023/02/05 22:39:04 - mmengine - INFO - Saving checkpoint at 15 epochs
2023/02/05 22:39:05 - mmengine - INFO - Epoch(val) [15][18/18]  accuracy/top1: 97.0070  accuracy/top5: 100.0000
